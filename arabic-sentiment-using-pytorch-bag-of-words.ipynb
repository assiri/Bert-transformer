{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-07-09T12:19:24.366334Z","iopub.status.busy":"2021-07-09T12:19:24.365900Z","iopub.status.idle":"2021-07-09T12:19:25.561762Z","shell.execute_reply":"2021-07-09T12:19:25.560650Z","shell.execute_reply.started":"2021-07-09T12:19:24.366248Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2990</th>\n","      <td>0</td>\n","      <td>رواية مختلفة تماما عما سبق من أحمد مراد. بصراح...</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>0</td>\n","      <td>الرواية مكتوبة باسهاب يبعث على الملل .. حيث ال...</td>\n","    </tr>\n","    <tr>\n","      <th>5095</th>\n","      <td>1</td>\n","      <td>لن أضيف الكثير إلى تعليقات الآخرين الكثير، سوى...</td>\n","    </tr>\n","    <tr>\n","      <th>3041</th>\n","      <td>0</td>\n","      <td>ضعيف جدا. . معاملة الريسيبشنيست العرب غير جيده...</td>\n","    </tr>\n","    <tr>\n","      <th>2753</th>\n","      <td>0</td>\n","      <td>الرواية رائعة بس النهاية متوقعة او مفتعلة شوية...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      label                                               text\n","2990      0  رواية مختلفة تماما عما سبق من أحمد مراد. بصراح...\n","764       0  الرواية مكتوبة باسهاب يبعث على الملل .. حيث ال...\n","5095      1  لن أضيف الكثير إلى تعليقات الآخرين الكثير، سوى...\n","3041      0  ضعيف جدا. . معاملة الريسيبشنيست العرب غير جيده...\n","2753      0  الرواية رائعة بس النهاية متوقعة او مفتعلة شوية..."]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["#!/usr/bin/python\n","# -*- coding: utf-8 -*-\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","df = pd.read_csv('5556-ar-reviews.csv')\n","df = df.sample(frac=1)\n","df.head()"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-07-09T12:19:25.564097Z","iopub.status.busy":"2021-07-09T12:19:25.563694Z","iopub.status.idle":"2021-07-09T12:19:25.572964Z","shell.execute_reply":"2021-07-09T12:19:25.571844Z","shell.execute_reply.started":"2021-07-09T12:19:25.564056Z"},"trusted":true},"outputs":[],"source":["\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.l1 = nn.Linear(input_size, hidden_size)\n","        self.l2 = nn.Linear(hidden_size, hidden_size)\n","        self.l3 = nn.Linear(hidden_size, num_classes)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        out = self.l1(x)\n","        out = self.relu(out)\n","        out = self.l2(out)\n","        out = self.relu(out)\n","        out = self.l3(out)\n","        # no activation and no softmax at the end\n","        return out"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-07-09T12:19:25.576106Z","iopub.status.busy":"2021-07-09T12:19:25.575483Z","iopub.status.idle":"2021-07-09T12:19:25.595366Z","shell.execute_reply":"2021-07-09T12:19:25.594512Z","shell.execute_reply.started":"2021-07-09T12:19:25.576058Z"},"trusted":true},"outputs":[],"source":["\n","\n","def bag_of_words(tokenized_sentence, words):\n","    \"\"\"\n","    return bag of words array:\n","    1 for each known word that exists in the sentence, 0 otherwise\n","    example:\n","    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n","    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n","    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n","    \"\"\"\n","    # stem each word\n","    sentence_words = [word for word in tokenized_sentence]\n","    # initialize bag with 0 for each word\n","    bag = np.zeros(len(words), dtype=np.float32)\n","    for idx, w in enumerate(words):\n","        if w in sentence_words:\n","            bag[idx] = 1\n","\n","    return bag\n","\n","\n","stopwords = {'فإذا', 'أنى', 'بمن', 'حتى', 'لم', 'أنتما', 'هناك', 'تينك', 'بل', 'إي', 'عن', 'ولكن', 'وإذا', 'دون', 'إنا', 'إذن', 'بكم', 'حين', 'عند', 'هل', 'إلا', 'هاته', 'ذينك', 'اللواتي', 'كذا', 'لستما', 'هي', 'اللتان', 'أكثر', 'كلتا', 'لكن', 'ليستا', 'هكذا', 'عسى', 'إذ', 'إن', 'اللاتي', 'إذا', 'بهم', 'نحن', 'فيما', 'ذاك', 'بكن', 'بيد', 'لهن', 'هذي', 'كأي', 'ذوا', 'أي', 'كلاهما', 'هذين', 'أينما', 'كي', 'إليكن', 'ماذا', 'هيا', 'هنالك', 'بي', 'بما', 'تلكما', 'بعض', 'بهن', 'تين', 'ريث', 'على', 'غير', 'حيثما', 'كأن', 'بخ', 'هاتان', 'هاهنا', 'ما', 'هيهات', 'لدى', 'شتان', 'لسنا', 'كيفما', 'مع', 'ممن', 'كما', 'إنما', 'يا', 'عليه', 'لك', 'ذه', 'ذان', 'لهما', 'ليست', 'لنا', 'مه', 'أنتن', 'في', 'لولا', 'بس', 'لها', 'أقل', 'عليك', 'فلا', 'مهما', 'ليسا', 'ذين', 'ذات', 'كلما', 'ذا', 'ذو', 'فيه', 'تي', 'هنا', 'هاتين', 'ها', 'هم', 'ألا', 'لا', 'سوى', 'وإذ', 'كم', 'لست', 'حيث', 'إليكما', 'لوما', 'الذين', 'كلا',\n","             'التي', 'كأين', 'ذواتي', 'لستم', 'هذا', 'فمن', 'ذلكم', 'وما', 'كيف', 'لكم', 'حاشا', 'بك', 'والذي', 'أن', 'لهم', 'لسن', 'ثمة', 'ذي', 'وإن', 'ومن', 'أيها', 'له', 'متى', 'بلى', 'اللتين', 'لستن', 'بكما', 'قد', 'كليكما', 'لكما', 'هلا', 'آي', 'لكنما', 'اللذين', 'اللائي', 'ذلكن', 'لاسيما', 'ذلك', 'مذ', 'اللتيا', 'هما', 'إليك', 'سوف', 'منها', 'والذين', 'أنتم', 'هاتي', 'لكي', 'اللذان', 'ذواتا', 'عما', 'فيها', 'إلى', 'تلك', 'كل', 'لي', 'هو', 'فيم', 'إليكم', 'بها', 'ذانك', 'إنه', 'هؤلاء', 'أولئك', 'إذما', 'بنا', 'من', 'خلا', 'ليسوا', 'ثم', 'لعل', 'وهو', 'نحو', 'أين', 'لئن', 'عدا', 'آه', 'كأنما', 'كليهما', 'الذي', 'لن', 'نعم', 'هذه', 'بهما', 'ليت', 'تلكم', 'أما', 'منذ', 'أو', 'هاك', 'بماذا', 'كذلك', 'أنا', 'آها', 'فإن', 'عل', 'منه', 'هيت', 'أف', 'أم', 'إيه', 'كيت', 'ته', 'لكيلا', 'ليس', 'مما', 'هذان', 'أنت', 'حبذا', 'ولو', 'أوه', 'إما', 'لو', 'بين', 'به', 'ولا', 'لما', 'بعد', 'هن', 'ذلكما', 'أولاء', 'و'}\n","\n","\n","def tokenize(sentence):\n","    tmpTokens = sentence.lower().split()\n","    tokens = [token for token in tmpTokens if (\n","        (token not in stopwords) and (len(token) > 0))]\n","\n","    return tokens"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-07-09T12:19:25.597447Z","iopub.status.busy":"2021-07-09T12:19:25.596786Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["66011 2\n"]}],"source":["\n","\n","all_words = []\n","tags = [0, 1]\n","xy = []\n","# loop through each sentence in our intents patterns\n","intents = df[[\"label\", \"text\"]].values\n","\n","for pattern in intents:\n","    tag = pattern[0]\n","    # tokenize each word in the sentence\n","    w = tokenize(pattern[1])\n","    # add to our words list\n","    all_words.extend(w)\n","    # add to xy pair\n","    xy.append((w, tag))\n","\n","# stem and lower each word\n","ignore_words = ['?', '.', '!']\n","all_words = [w for w in all_words if w not in ignore_words]\n","# remove duplicates and sort\n","all_words = sorted(set(all_words))\n","tags = sorted(set(tags))\n","\n","X_train = []\n","y_train = []\n","for (pattern_sentence, tag) in xy:\n","    # X: bag of words for each pattern_sentence\n","    bag = bag_of_words(pattern_sentence, all_words)\n","    X_train.append(bag)\n","    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n","    label = tags.index(tag)\n","    y_train.append(label)\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","\n","# Hyper-parameters\n","num_epochs = 100\n","batch_size = 64\n","learning_rate = 0.001\n","input_size = len(X_train[0])\n","hidden_size = 8\n","output_size = len(tags)\n","print(input_size, output_size)  # 59915 2\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [5/100], Loss: 0.0007\n","Epoch [10/100], Loss: 0.0001\n","Epoch [15/100], Loss: 0.0001\n","Epoch [20/100], Loss: 0.0001\n","Epoch [25/100], Loss: 0.0000\n","Epoch [30/100], Loss: 0.0000\n","Epoch [35/100], Loss: 0.0000\n","Epoch [40/100], Loss: 0.0000\n","Epoch [45/100], Loss: 0.0000\n","Epoch [50/100], Loss: 0.0000\n","Epoch [55/100], Loss: 0.0000\n","Epoch [60/100], Loss: 0.0000\n","Epoch [65/100], Loss: 0.0000\n","Epoch [70/100], Loss: 0.0000\n","Epoch [75/100], Loss: 0.0000\n","Epoch [80/100], Loss: 0.0000\n","Epoch [85/100], Loss: 0.0000\n","Epoch [90/100], Loss: 0.0000\n","Epoch [95/100], Loss: 0.0000\n","Epoch [100/100], Loss: 0.0000\n","final loss: 0.0000\n","training complete. file saved to data2.pth\n"]}],"source":["\n","class ReviewsDataset(Dataset):\n","\n","    def __init__(self):\n","        self.n_samples = len(X_train)\n","        self.x_data = X_train\n","        self.y_data = y_train\n","\n","    # support indexing such that dataset[i] can be used to get i-th sample\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    # we can call len(dataset) to return the size\n","    def __len__(self):\n","        return self.n_samples\n","\n","\n","dataset = ReviewsDataset()\n","train_loader = DataLoader(dataset=dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          num_workers=0)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    for idx, (words, labels) in enumerate(train_loader):\n","        words = words.to(device)\n","        labels = labels.to(dtype=torch.long).to(device)\n","\n","        # Forward pass\n","        outputs = model(words)\n","        # if y would be one-hot, we must apply\n","        # labels = torch.max(labels, 1)[1]\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    if (epoch+1) % 5 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()/idx:.4f}')\n","\n","\n","print(f'final loss: {loss.item():.4f}')\n","\n","data = {\n","    \"model_state\": model.state_dict(),\n","    \"input_size\": input_size,\n","    \"hidden_size\": hidden_size,\n","    \"output_size\": output_size,\n","    \"all_words\": all_words,\n","    \"tags\": tags\n","}\n","\n","FILE = \"data2.pth\"\n","torch.save(data, FILE)\n","\n","print(f'training complete. file saved to {FILE}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Prediction"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" 1 \n"]}],"source":["sentence= \"رحلاتي القادمة الى الرياض عندهم أن شاء الله . . طاقم العمل رائع كلهم ا.وائل و اثنين شباب في فترة الصباح ناسي اسمهم . تقديم ضيافة عند القدوم صباحا . تقديم ضيافة في المساء شاي و قهوة عربي مع تمر . راحة و نظافة المكان جدا جدا نظيف و خدمة الغرف سريعة . موقعه مناسب للأشخاص اهتمامهم السفارات او الجامعة قريب منها و لكن بعيد عن شرق الرياض . سهولة الوصول الى الدائري الشمالي . هدوء المكان . جميع الخدمات حولك . المسجد مقابل الفندق. لا يوجد شي سي ابدا\" \n","\n","sentence = tokenize(sentence)\n","X = bag_of_words(sentence, all_words)\n","X = X.reshape(1, X.shape[0])\n","X = torch.from_numpy(X).to(device)\n","\n","output = model(X)\n","_, predicted = torch.max(output, dim=1)\n","\n","tag = tags[predicted.item()]\n","\n","probs = torch.softmax(output, dim=1)\n","prob = probs[0][predicted.item()]\n","if prob.item() > 0.75:\n","    for intent in intents:\n","        if tag == intent[0]:\n","            print(f\" {tag} \")\n","            break\n","else:\n","    print(\"I do not understand...\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
